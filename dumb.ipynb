{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1457,"sourceType":"datasetVersion","datasetId":781}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stupid word generation with markov chains","metadata":{}},{"cell_type":"markdown","source":"**WHY?**\nBecause I can and most of LLMs are not funny enough","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:40:37.398144Z","iopub.execute_input":"2024-12-04T02:40:37.398525Z","iopub.status.idle":"2024-12-04T02:40:37.438918Z","shell.execute_reply.started":"2024-12-04T02:40:37.398488Z","shell.execute_reply":"2024-12-04T02:40:37.437526Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/short-jokes/shortjokes.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:40:37.441230Z","iopub.execute_input":"2024-12-04T02:40:37.442025Z","iopub.status.idle":"2024-12-04T02:40:49.949602Z","shell.execute_reply.started":"2024-12-04T02:40:37.441969Z","shell.execute_reply":"2024-12-04T02:40:49.948205Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport random\nfrom nltk import bigrams, trigrams\nfrom nltk.corpus import stopwords\nfrom collections import defaultdict, Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:40:49.951545Z","iopub.execute_input":"2024-12-04T02:40:49.952114Z","iopub.status.idle":"2024-12-04T02:40:53.883489Z","shell.execute_reply.started":"2024-12-04T02:40:49.952054Z","shell.execute_reply":"2024-12-04T02:40:53.882150Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:40:53.886197Z","iopub.execute_input":"2024-12-04T02:40:53.886728Z","iopub.status.idle":"2024-12-04T02:40:54.074655Z","shell.execute_reply.started":"2024-12-04T02:40:53.886690Z","shell.execute_reply":"2024-12-04T02:40:54.073532Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/short-jokes/shortjokes.csv')\ntokenized_jokes = [nltk.word_tokenize(jokes.lower()) for jokes in df['Joke']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:41:27.794684Z","iopub.execute_input":"2024-12-04T02:41:27.795237Z","iopub.status.idle":"2024-12-04T02:42:18.342304Z","shell.execute_reply.started":"2024-12-04T02:41:27.795185Z","shell.execute_reply":"2024-12-04T02:42:18.340454Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def build_transition_matrix(texts):\n    transition_matrix = defaultdict(Counter)\n    for sentence in texts:\n        for word1, word2 in zip(sentence, sentence[1:]):\n            transition_matrix[word1][word2] += 1\n    for word1 in transition_matrix:\n        total = sum(transition_matrix[word1].values())\n        for word2 in transition_matrix[word1]:\n            transition_matrix[word1][word2] /= total\n    return transition_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:42:40.700970Z","iopub.execute_input":"2024-12-04T02:42:40.701417Z","iopub.status.idle":"2024-12-04T02:42:40.708443Z","shell.execute_reply.started":"2024-12-04T02:42:40.701381Z","shell.execute_reply":"2024-12-04T02:42:40.707162Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Build transition matrix for jokes\njoke_matrix = build_transition_matrix(tokenized_jokes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:42:46.315472Z","iopub.execute_input":"2024-12-04T02:42:46.315923Z","iopub.status.idle":"2024-12-04T02:42:50.843630Z","shell.execute_reply.started":"2024-12-04T02:42:46.315886Z","shell.execute_reply":"2024-12-04T02:42:50.842299Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def generate_text(start_word, transition_matrix, length=15):\n    current_word = start_word\n    generated_text = [current_word]\n    \n    for _ in range(length - 1):\n        next_word_probs = transition_matrix.get(current_word, {})\n        if not next_word_probs:\n            break\n        next_word = random.choices(list(next_word_probs.keys()), weights=next_word_probs.values())[0]\n        generated_text.append(next_word)\n        current_word = next_word\n\n    return ' '.join(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:43:21.669289Z","iopub.execute_input":"2024-12-04T02:43:21.669729Z","iopub.status.idle":"2024-12-04T02:43:21.677652Z","shell.execute_reply.started":"2024-12-04T02:43:21.669691Z","shell.execute_reply":"2024-12-04T02:43:21.676157Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def generate_joke_from_prompt(prompt):\n    prompt_tokens = nltk.word_tokenize(prompt.lower())\n    start_word = prompt_tokens[0]  # Use the first word of the prompt as the start of the joke\n    joke = generate_text(start_word, joke_matrix, length=20)\n    \n    return joke.capitalize()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:43:18.374746Z","iopub.execute_input":"2024-12-04T02:43:18.375200Z","iopub.status.idle":"2024-12-04T02:43:18.383186Z","shell.execute_reply.started":"2024-12-04T02:43:18.375162Z","shell.execute_reply":"2024-12-04T02:43:18.381643Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Example usage: Get a joke based on a user prompt\nuser_prompt = \"Sadness\"\ngenerated_joke = generate_joke_from_prompt(user_prompt)\nprint(generated_joke)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:50:12.517186Z","iopub.execute_input":"2024-12-04T02:50:12.517612Z","iopub.status.idle":"2024-12-04T02:50:12.531503Z","shell.execute_reply.started":"2024-12-04T02:50:12.517577Z","shell.execute_reply":"2024-12-04T02:50:12.530113Z"}},"outputs":[{"name":"stdout","text":"Sadness to hundreds and one . whenever i 'll do porn stars ... that sticks to have no one torta\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import pickle\n\nwith open('markov_chain_model.pkl', 'wb') as f:\n    pickle.dump(joke_matrix, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T02:51:40.350475Z","iopub.execute_input":"2024-12-04T02:51:40.350934Z","iopub.status.idle":"2024-12-04T02:51:41.560455Z","shell.execute_reply.started":"2024-12-04T02:51:40.350897Z","shell.execute_reply":"2024-12-04T02:51:41.559053Z"}},"outputs":[{"name":"stdout","text":"Markov Chain model saved.\n","output_type":"stream"}],"execution_count":62}]}